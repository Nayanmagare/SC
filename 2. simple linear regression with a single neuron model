# Step 1: Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Step 2: Create synthetic dataset (X = Feature, y = Target variable)
np.random.seed(42)  # For reproducibility

# Create random data for X (feature)
X = np.random.rand(100, 1) * 10  # 100 samples, feature between 0 and 10
# Create a target variable 'y' using a linear relation with some noise
y = 2.5 * X + np.random.randn(100, 1) * 2  # Linear relation with noise

# Step 3: Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 5: Make predictions on the test data
y_test_pred = model.predict(X_test)

# Step 6: Evaluate the model performance on the test data
test_mse = mean_squared_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

# Print performance metrics
print(f'Test Mean Squared Error (MSE): {test_mse:.2f}')
print(f'Test R-squared: {test_r2:.2f}')

# Step 7: Visualize the results - Plotting the regression line for testing data

# Plot for Testing Data
plt.figure(figsize=(8, 6))
plt.scatter(X_test, y_test, color='green', label='Test data')  # Test data points
plt.plot(X_test, y_test_pred, color='red', label='Regression line')  # Predicted regression line
plt.title('Linear Regression - Test Data')
plt.xlabel('Feature (X)')
plt.ylabel('Target (y)')
plt.legend()

# Show the plot
plt.tight_layout()
plt.show()
